#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸­é‡‘æ‰€æŒä»“æ•°æ®çˆ¬è™«ç¨‹åº
ç›®æ ‡ç½‘ç«™: http://www.cffex.com.cn/ccpm/?productid=IM
åŠŸèƒ½: çˆ¬å–æœŸè´§æŒä»“æ’åæ•°æ®
"""

import requests
import json
import pandas as pd
from datetime import datetime, timedelta
import time
import re
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('cffex_spider.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class CFFEXSpider:
    def __init__(self, headless=True):
        """
        åˆå§‹åŒ–çˆ¬è™«
        Args:
            headless: æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼
        """
        self.base_url = "http://www.cffex.com.cn/ccpm/"
        self.session = requests.Session()
        self.setup_headers()
        self.setup_driver(headless)
        
    def setup_headers(self):
        """è®¾ç½®è¯·æ±‚å¤´"""
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
    
    def setup_driver(self, headless=True):
        """è®¾ç½®Selenium WebDriver"""
        try:
            chrome_options = Options()
            if headless:
                chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
            
            self.driver = webdriver.Chrome(options=chrome_options)
            self.wait = WebDriverWait(self.driver, 10)
            logging.info("WebDriveråˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logging.error(f"WebDriveråˆå§‹åŒ–å¤±è´¥: {e}")
            self.driver = None
    
    def get_product_data(self, product_id="IM", date=None, contract_month=None):
        """
        è·å–æŒ‡å®šäº§å“çš„æŒä»“æ•°æ®
        Args:
            product_id: äº§å“ID (IM=ä¸­è¯1000è‚¡æŒ‡æœŸè´§)
            date: æŸ¥è¯¢æ—¥æœŸï¼Œæ ¼å¼YYYY-MM-DDï¼Œé»˜è®¤ä¸ºæœ€æ–°äº¤æ˜“æ—¥
            contract_month: åˆçº¦æœˆä»½ï¼Œå¦‚"2024-12"ï¼Œé»˜è®¤ä¸ºä¸»åŠ›åˆçº¦
        Returns:
            dict: åŒ…å«æŒä»“æ•°æ®çš„å­—å…¸
        """
        try:
            # æ„é€ é¡µé¢URL
            page_url = f"http://www.cffex.com.cn/ccpm/?productid={product_id}"
            logging.info(f"æ­£åœ¨è®¿é—®é¡µé¢: {page_url}")
            
            # è®¿é—®é¡µé¢
            self.driver.get(page_url)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            time.sleep(3)
            
            # è®¾ç½®æ—¥æœŸ
            if date:
                try:
                    date_input = WebDriverWait(self.driver, 10).until(
                        EC.presence_of_element_located((By.ID, "inputdate"))
                    )
                    # æ¸…ç©ºå¹¶è¾“å…¥æ—¥æœŸ
                    date_input.clear()
                    date_input.send_keys(date)
                    logging.info(f"å·²è®¾ç½®æ—¥æœŸ: {date}")
                except Exception as e:
                    logging.warning(f"è®¾ç½®æ—¥æœŸå¤±è´¥: {e}")
            
            # ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®
            try:
                query_button = self.driver.find_element(By.XPATH, "//button[contains(text(), 'æŸ¥è¯¢')]")
                query_button.click()
                logging.info("å·²ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®")
                
                # ç­‰å¾…æ•°æ®åŠ è½½
                time.sleep(5)
            except Exception as e:
                logging.warning(f"ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®å¤±è´¥: {e}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰"æ— æ•°æ®"æç¤º
            try:
                no_data_element = self.driver.find_element(By.CLASS_NAME, "no_data")
                if no_data_element.is_displayed() and no_data_element.text.strip():
                    logging.info("é¡µé¢æ˜¾ç¤ºæ— æ•°æ®")
                    return {
                        "success": False,
                        "error": f"è¯¥æ—¥æœŸ({date or 'latest'})æ— æ•°æ®",
                        "product_id": product_id,
                        "date": date or 'latest'
                    }
            except:
                pass  # æ²¡æœ‰æ‰¾åˆ°æ— æ•°æ®æç¤ºï¼Œç»§ç»­å¤„ç†
            
            # ç­‰å¾…æ•°æ®è¡¨æ ¼åŠ è½½
            try:
                # å…ˆç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
                time.sleep(3)
                
                # å°è¯•å¤šç§å¯èƒ½çš„è¡¨æ ¼é€‰æ‹©å™¨
                table_selectors = [
                    "//table[contains(@class, 'table')]",
                    "//table",
                    "//div[contains(@class, 'table')]//table",
                    "//div[@id='data']//table",
                    "//div[contains(@class, 'data')]//table"
                ]
                
                table_found = False
                for selector in table_selectors:
                    try:
                        WebDriverWait(self.driver, 5).until(
                            EC.presence_of_element_located((By.XPATH, selector))
                        )
                        logging.info(f"æ•°æ®è¡¨æ ¼å·²åŠ è½½ï¼Œä½¿ç”¨é€‰æ‹©å™¨: {selector}")
                        table_found = True
                        break
                    except:
                        continue
                
                if not table_found:
                    # å¦‚æœæ‰¾ä¸åˆ°è¡¨æ ¼ï¼Œæ‰“å°é¡µé¢æºç ç”¨äºè°ƒè¯•
                    logging.warning("æœªæ‰¾åˆ°æ•°æ®è¡¨æ ¼ï¼Œæ‰“å°é¡µé¢å†…å®¹ç”¨äºè°ƒè¯•")
                    page_source = self.driver.page_source
                    logging.debug(f"é¡µé¢æºç : {page_source[:2000]}...")  # åªæ‰“å°å‰2000å­—ç¬¦
                    
            except Exception as e:
                logging.warning(f"ç­‰å¾…æ•°æ®è¡¨æ ¼è¶…æ—¶: {e}")
            
            # è§£æé¡µé¢æ•°æ®
            parsed_data = self.parse_page_data()
            
            if parsed_data and any(parsed_data.values()):
                logging.info(f"æˆåŠŸè·å–æ•°æ®: {product_id}, æ—¥æœŸ: {date or 'latest'}")
                return {
                    "success": True,
                    "data": parsed_data,
                    "product_id": product_id,
                    "date": date or 'latest',
                    "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
            else:
                logging.error("æœªèƒ½è·å–åˆ°æœ‰æ•ˆæ•°æ®")
                return {
                    "success": False,
                    "error": "æœªèƒ½è·å–åˆ°æœ‰æ•ˆæ•°æ®",
                    "product_id": product_id,
                    "date": date or 'latest'
                }
                
        except Exception as e:
            logging.error(f"è·å–æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return {
                "success": False,
                "error": f"è·å–æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}",
                "product_id": product_id,
                "date": date or 'latest'
            }
    
    def parse_page_data(self):
        """
        è§£æé¡µé¢ä¸­çš„æˆäº¤æŒä»“æ’åæ•°æ®
        Returns:
            dict: è§£æåçš„æ•°æ®
        """
        try:
            result = {
                "volume_ranking": [],      # æˆäº¤é‡æ’å
                "buy_position_ranking": [], # æŒä¹°å•é‡æ’å  
                "sell_position_ranking": [] # æŒå–å•é‡æ’å
            }
            
            # å°è¯•å¤šç§å¯èƒ½çš„è¡¨æ ¼é€‰æ‹©å™¨
            table_selectors = [
                "//table[contains(@class, 'table')]",
                "//table",
                "//div[contains(@class, 'table')]//table",
                "//div[@id='data']//table",
                "//div[contains(@class, 'data')]//table"
            ]
            
            tables = []
            for selector in table_selectors:
                try:
                    found_tables = self.driver.find_elements(By.XPATH, selector)
                    if found_tables:
                        tables = found_tables
                        logging.info(f"æ‰¾åˆ° {len(tables)} ä¸ªè¡¨æ ¼ï¼Œä½¿ç”¨é€‰æ‹©å™¨: {selector}")
                        break
                except:
                    continue
            
            if not tables:
                logging.warning("æœªæ‰¾åˆ°ä»»ä½•æ•°æ®è¡¨æ ¼")
                # å°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„æ•°æ®å®¹å™¨
                try:
                    # æŸ¥æ‰¾å¯èƒ½åŒ…å«æ•°æ®çš„divå…ƒç´ 
                    data_divs = self.driver.find_elements(By.XPATH, "//div[contains(@class, 'data') or contains(@id, 'data')]")
                    if data_divs:
                        logging.info(f"æ‰¾åˆ° {len(data_divs)} ä¸ªæ•°æ®å®¹å™¨")
                        for div in data_divs:
                            logging.debug(f"æ•°æ®å®¹å™¨å†…å®¹: {div.text[:200]}...")
                except:
                    pass
                return result
            
            for i, table in enumerate(tables):
                try:
                    # è·å–è¡¨æ ¼æ ‡é¢˜æˆ–ç±»å‹
                    table_type = None
                    
                    # å°è¯•ä»è¡¨æ ¼å‰çš„æ ‡é¢˜è·å–ç±»å‹
                    try:
                        # æŸ¥æ‰¾è¡¨æ ¼å‰é¢çš„æ ‡é¢˜å…ƒç´ 
                        title_elements = self.driver.find_elements(By.XPATH, f"//table[{i+1}]/preceding-sibling::*")
                        for title_element in title_elements[-3:]:  # æ£€æŸ¥å‰3ä¸ªå…„å¼Ÿå…ƒç´ 
                            title_text = title_element.text.strip()
                            if title_text:
                                logging.info(f"è¡¨æ ¼ {i} æ ‡é¢˜: {title_text}")
                                if "æˆäº¤é‡" in title_text:
                                    table_type = "volume_ranking"
                                elif "æŒä¹°" in title_text or "ä¹°å•" in title_text:
                                    table_type = "buy_position_ranking"
                                elif "æŒå–" in title_text or "å–å•" in title_text:
                                    table_type = "sell_position_ranking"
                                break
                    except Exception as e:
                        logging.debug(f"è·å–è¡¨æ ¼æ ‡é¢˜å¤±è´¥: {e}")
                    
                    # å¦‚æœæ— æ³•ä»æ ‡é¢˜åˆ¤æ–­ï¼Œæ ¹æ®è¡¨æ ¼é¡ºåºåˆ¤æ–­
                    if not table_type:
                        if i == 0:
                            table_type = "volume_ranking"
                        elif i == 1:
                            table_type = "buy_position_ranking"
                        elif i == 2:
                            table_type = "sell_position_ranking"
                        else:
                            continue
                    
                    logging.info(f"è§£æè¡¨æ ¼ {i}ï¼Œç±»å‹: {table_type}")
                    
                    # è§£æè¡¨æ ¼æ•°æ®
                    rows = table.find_elements(By.TAG_NAME, "tr")
                    logging.info(f"è¡¨æ ¼ {i} å…±æœ‰ {len(rows)} è¡Œ")
                    
                    if len(rows) <= 1:  # åªæœ‰è¡¨å¤´æˆ–æ²¡æœ‰æ•°æ®
                        logging.warning(f"è¡¨æ ¼ {i} æ²¡æœ‰æ•°æ®è¡Œ")
                        continue
                    
                    for row_idx, row in enumerate(rows[1:], 1):  # è·³è¿‡è¡¨å¤´
                        cells = row.find_elements(By.TAG_NAME, "td")
                        if len(cells) >= 4:
                            record = {
                                "rank": cells[0].text.strip(),
                                "member_name": cells[1].text.strip(),
                                "volume": cells[2].text.strip(),
                                "change": cells[3].text.strip()
                            }
                            result[table_type].append(record)
                            logging.debug(f"è¡¨æ ¼ {i} ç¬¬ {row_idx} è¡Œ: {record}")
                        else:
                            logging.debug(f"è¡¨æ ¼ {i} ç¬¬ {row_idx} è¡Œåˆ—æ•°ä¸è¶³: {len(cells)}")
                    
                    logging.info(f"è§£æè¡¨æ ¼ {table_type}: {len(result[table_type])} æ¡è®°å½•")
                    
                except Exception as e:
                    logging.warning(f"è§£æè¡¨æ ¼ {i} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    continue
            
            # ç»Ÿè®¡æ€»è®°å½•æ•°
            total_records = sum(len(records) for records in result.values())
            logging.info(f"æ€»å…±è§£æåˆ° {total_records} æ¡è®°å½•")
            
            return result
            
        except Exception as e:
            logging.error(f"è§£æé¡µé¢æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
        """
        è‡ªåŠ¨ç‚¹å‡»é€‰æ‹©æ—¥æœŸå’Œåˆçº¦
        Args:
            target_date: ç›®æ ‡æ—¥æœŸï¼Œæ ¼å¼YYYY-MM-DD
            contract_month: åˆçº¦æœˆä»½ï¼Œå¦‚"2024-12"
        Returns:
            bool: æ“ä½œæ˜¯å¦æˆåŠŸ
        """
        try:
            success_count = 0
            
            # 1. å¤„ç†æ—¥æœŸé€‰æ‹©
            if target_date:
                date_success = self.click_date_selector(target_date)
                if date_success:
                    success_count += 1
                    logging.info(f"æˆåŠŸé€‰æ‹©æ—¥æœŸ: {target_date}")
                else:
                    logging.warning(f"é€‰æ‹©æ—¥æœŸå¤±è´¥: {target_date}")
            
            # 2. å¤„ç†åˆçº¦é€‰æ‹©
            if contract_month:
                contract_success = self.click_contract_selector(contract_month)
                if contract_success:
                    success_count += 1
                    logging.info(f"æˆåŠŸé€‰æ‹©åˆçº¦: {contract_month}")
                else:
                    logging.warning(f"é€‰æ‹©åˆçº¦å¤±è´¥: {contract_month}")
            
            # 3. ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®
            query_success = self.click_query_button()
            if query_success:
                success_count += 1
                logging.info("æˆåŠŸç‚¹å‡»æŸ¥è¯¢æŒ‰é’®")
            else:
                logging.warning("ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®å¤±è´¥")
            
            return success_count > 0
            
        except Exception as e:
            logging.error(f"è‡ªåŠ¨ç‚¹å‡»æ“ä½œå‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def click_date_selector(self, target_date):
        """ç‚¹å‡»æ—¥æœŸé€‰æ‹©å™¨"""
        try:
            # ä¸“é—¨é’ˆå¯¹CFFEXç½‘ç«™çš„My97DatePickeræ—¥æœŸé€‰æ‹©å™¨
            try:
                # é¦–å…ˆå°è¯•æ‰¾åˆ°actualDateè¾“å…¥æ¡†
                date_element = self.wait.until(EC.element_to_be_clickable((By.ID, "actualDate")))
                
                # æ¸…ç©ºå¹¶è¾“å…¥æ—¥æœŸ
                date_element.clear()
                time.sleep(0.5)
                
                # è½¬æ¢æ—¥æœŸæ ¼å¼ä¸ºYYYY-MM-DD
                formatted_date = target_date
                date_element.send_keys(formatted_date)
                
                # è§¦å‘å¤šç§äº‹ä»¶ç¡®ä¿æ—¥æœŸè¢«æ­£ç¡®è®¾ç½®
                self.driver.execute_script("""
                    var element = arguments[0];
                    var date = arguments[1];
                    element.value = date;
                    element.dispatchEvent(new Event('input', {bubbles: true}));
                    element.dispatchEvent(new Event('change', {bubbles: true}));
                    element.dispatchEvent(new Event('blur', {bubbles: true}));
                """, date_element, formatted_date)
                
                time.sleep(1)
                logging.info(f"æˆåŠŸè®¾ç½®æ—¥æœŸä¸º: {formatted_date}")
                return True
                
            except (TimeoutException, NoSuchElementException):
                logging.warning("æœªæ‰¾åˆ°actualDateè¾“å…¥æ¡†ï¼Œå°è¯•å…¶ä»–æ—¥æœŸé€‰æ‹©å™¨")
            
            # å¤‡ç”¨çš„æ—¥æœŸé€‰æ‹©å™¨å®šä½æ–¹å¼
            date_selectors = [
                "//input[@name='actualDate']",
                "//input[contains(@class, 'Wdate')]",
                "//input[@type='text' and contains(@onfocus, 'WdatePicker')]",
                "//input[@type='date']",
                "//input[contains(@class, 'date')]",
                "//input[contains(@id, 'date')]",
                "//input[contains(@name, 'date')]"
            ]
            
            for selector in date_selectors:
                try:
                    date_element = self.wait.until(EC.element_to_be_clickable((By.XPATH, selector)))
                    
                    # æ¸…ç©ºå¹¶è¾“å…¥æ—¥æœŸ
                    date_element.clear()
                    time.sleep(0.5)
                    date_element.send_keys(target_date)
                    
                    # è§¦å‘äº‹ä»¶
                    self.driver.execute_script("""
                        var element = arguments[0];
                        var date = arguments[1];
                        element.value = date;
                        element.dispatchEvent(new Event('input', {bubbles: true}));
                        element.dispatchEvent(new Event('change', {bubbles: true}));
                        element.dispatchEvent(new Event('blur', {bubbles: true}));
                    """, date_element, target_date)
                    
                    time.sleep(1)
                    logging.info(f"é€šè¿‡é€‰æ‹©å™¨ {selector} æˆåŠŸè®¾ç½®æ—¥æœŸä¸º: {target_date}")
                    return True
                    
                except (TimeoutException, NoSuchElementException):
                    continue
            
            logging.warning("æ‰€æœ‰æ—¥æœŸé€‰æ‹©å™¨å°è¯•éƒ½å¤±è´¥äº†")
            return False
            
        except Exception as e:
            logging.error(f"ç‚¹å‡»æ—¥æœŸé€‰æ‹©å™¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def click_contract_selector(self, contract_month):
        """ç‚¹å‡»åˆçº¦é€‰æ‹©å™¨"""
        try:
            # å¸¸è§çš„åˆçº¦é€‰æ‹©å™¨å…ƒç´ å®šä½æ–¹å¼
            contract_selectors = [
                "//select[contains(@name, 'contract')]",
                "//select[contains(@id, 'contract')]",
                "//select[contains(@class, 'contract')]",
                "//div[contains(@class, 'contract-select')]//select",
                "//div[contains(@class, 'dropdown')]//select"
            ]
            
            for selector in contract_selectors:
                try:
                    select_element = self.wait.until(EC.element_to_be_clickable((By.XPATH, selector)))
                    
                    # ä½¿ç”¨Seleniumçš„Selectç±»
                    from selenium.webdriver.support.ui import Select
                    select = Select(select_element)
                    
                    # å°è¯•æŒ‰å€¼é€‰æ‹©
                    try:
                        select.select_by_value(contract_month)
                        return True
                    except:
                        pass
                    
                    # å°è¯•æŒ‰å¯è§æ–‡æœ¬é€‰æ‹©
                    try:
                        select.select_by_visible_text(contract_month)
                        return True
                    except:
                        pass
                    
                    # å°è¯•éƒ¨åˆ†åŒ¹é…
                    for option in select.options:
                        if contract_month in option.text or contract_month in option.get_attribute('value'):
                            option.click()
                            return True
                    
                except (TimeoutException, NoSuchElementException):
                    continue
            
            # å°è¯•ç‚¹å‡»åˆçº¦é“¾æ¥æˆ–æŒ‰é’®
            contract_links = [
                f"//a[contains(text(), '{contract_month}')]",
                f"//button[contains(text(), '{contract_month}')]",
                f"//span[contains(text(), '{contract_month}')]",
                f"//li[contains(text(), '{contract_month}')]",
                f"//option[contains(text(), '{contract_month}')]"
            ]
            
            for link_selector in contract_links:
                try:
                    contract_link = self.wait.until(EC.element_to_be_clickable((By.XPATH, link_selector)))
                    contract_link.click()
                    time.sleep(1)
                    return True
                except (TimeoutException, NoSuchElementException):
                    continue
            
            return False
            
        except Exception as e:
            logging.error(f"ç‚¹å‡»åˆçº¦é€‰æ‹©å™¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def click_query_button(self):
        """ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®"""
        try:
            # ä¸“é—¨é’ˆå¯¹CFFEXç½‘ç«™çš„æŸ¥è¯¢æŒ‰é’®
            try:
                # é¦–å…ˆå°è¯•æ‰¾åˆ°å…·æœ‰data-bind="click:getDatas"çš„æŒ‰é’®
                query_button = self.wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, "button.btn-query[data-bind*='getDatas']")))
                query_button.click()
                time.sleep(3)  # ç­‰å¾…æŸ¥è¯¢ç»“æœåŠ è½½
                logging.info("æˆåŠŸç‚¹å‡»æŸ¥è¯¢æŒ‰é’®")
                return True
                
            except (TimeoutException, NoSuchElementException):
                logging.warning("æœªæ‰¾åˆ°ä¸»æŸ¥è¯¢æŒ‰é’®ï¼Œå°è¯•å…¶ä»–æŸ¥è¯¢æŒ‰é’®")
            
            # å¤‡ç”¨çš„æŸ¥è¯¢æŒ‰é’®å®šä½æ–¹å¼
            query_selectors = [
                "//button[contains(@class, 'btn-query')]",
                "//button[contains(text(), 'æŸ¥è¯¢')]",
                "//input[@type='submit' and contains(@value, 'æŸ¥è¯¢')]",
                "//input[@type='button' and contains(@value, 'æŸ¥è¯¢')]",
                "//button[contains(@data-bind, 'getDatas')]",
                "//a[contains(text(), 'æŸ¥è¯¢')]",
                "//span[contains(text(), 'æŸ¥è¯¢')]"
            ]
            
            for selector in query_selectors:
                try:
                    query_button = self.wait.until(EC.element_to_be_clickable((By.XPATH, selector)))
                    
                    # ä½¿ç”¨JavaScriptç‚¹å‡»ï¼Œé¿å…å…ƒç´ è¢«é®æŒ¡çš„é—®é¢˜
                    self.driver.execute_script("arguments[0].click();", query_button)
                    time.sleep(3)  # ç­‰å¾…æŸ¥è¯¢ç»“æœåŠ è½½
                    
                    logging.info(f"é€šè¿‡é€‰æ‹©å™¨ {selector} æˆåŠŸç‚¹å‡»æŸ¥è¯¢æŒ‰é’®")
                    return True
                    
                except (TimeoutException, NoSuchElementException):
                    continue
            
            # å¦‚æœæ²¡æ‰¾åˆ°æŸ¥è¯¢æŒ‰é’®ï¼Œå°è¯•æŒ‰å›è½¦é”®è§¦å‘æŸ¥è¯¢
            try:
                from selenium.webdriver.common.keys import Keys
                body = self.driver.find_element(By.TAG_NAME, "body")
                body.send_keys(Keys.ENTER)
                time.sleep(3)
                logging.info("é€šè¿‡å›è½¦é”®è§¦å‘æŸ¥è¯¢")
                return True
            except:
                pass
            
            logging.warning("æ‰€æœ‰æŸ¥è¯¢æŒ‰é’®å°è¯•éƒ½å¤±è´¥äº†")
            return False
            
        except Exception as e:
            logging.error(f"ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def parse_table(self, table_element):
        """è§£æHTMLè¡¨æ ¼"""
        try:
            rows = table_element.find_elements(By.TAG_NAME, "tr")
            if len(rows) < 2:  # è‡³å°‘éœ€è¦è¡¨å¤´å’Œä¸€è¡Œæ•°æ®
                return None
            
            # è·å–è¡¨å¤´
            headers = []
            header_row = rows[0]
            header_cells = header_row.find_elements(By.TAG_NAME, "th")
            if not header_cells:
                header_cells = header_row.find_elements(By.TAG_NAME, "td")
            
            for cell in header_cells:
                headers.append(cell.text.strip())
            
            if not headers:
                return None
            
            # è·å–æ•°æ®è¡Œ
            data_rows = []
            for row in rows[1:]:
                cells = row.find_elements(By.TAG_NAME, "td")
                if len(cells) == len(headers):
                    row_data = {}
                    for i, cell in enumerate(cells):
                        row_data[headers[i]] = cell.text.strip()
                    data_rows.append(row_data)
            
            return {
                "headers": headers,
                "rows": data_rows,
                "total_rows": len(data_rows)
            }
            
        except Exception as e:
            logging.error(f"è§£æè¡¨æ ¼æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    def parse_data_container(self, container_element):
        """è§£ææ•°æ®å®¹å™¨"""
        try:
            # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…çš„HTMLç»“æ„æ¥è§£æ
            text_content = container_element.text
            if text_content and len(text_content.strip()) > 0:
                return {"content": text_content.strip()}
            return None
        except Exception as e:
            logging.error(f"è§£ææ•°æ®å®¹å™¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    def check_ajax_requests(self, product_id, date):
        """æ£€æŸ¥å¹¶å°è¯•è·å–Ajaxè¯·æ±‚çš„æ•°æ®"""
        try:
            # æ‰§è¡ŒJavaScriptæ¥è·å–å¯èƒ½çš„Ajaxæ•°æ®
            script = """
            var ajaxData = null;
            if (typeof window.ajaxResponse !== 'undefined') {
                ajaxData = window.ajaxResponse;
            }
            return ajaxData;
            """
            ajax_result = self.driver.execute_script(script)
            
            if ajax_result:
                return {"ajax_data": ajax_result}
            
            # å°è¯•ç›´æ¥è¯·æ±‚å¯èƒ½çš„APIç«¯ç‚¹
            api_endpoints = [
                f"/api/ccpm/data?productid={product_id}",
                f"/ccpm/api/data?productid={product_id}",
                f"/data/ccpm?productid={product_id}"
            ]
            
            for endpoint in api_endpoints:
                try:
                    api_url = f"http://www.cffex.com.cn{endpoint}"
                    if date:
                        api_url += f"&date={date}"
                    
                    response = self.session.get(api_url, timeout=10)
                    if response.status_code == 200:
                        try:
                            json_data = response.json()
                            return {"api_data": json_data, "endpoint": endpoint}
                        except:
                            if response.text and len(response.text.strip()) > 0:
                                return {"api_text": response.text, "endpoint": endpoint}
                except:
                    continue
            
            return None
            
        except Exception as e:
            logging.error(f"æ£€æŸ¥Ajaxè¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    def get_available_products(self):
        """è·å–å¯ç”¨çš„äº§å“åˆ—è¡¨"""
        products = {
            "IF": "æ²ªæ·±300è‚¡æŒ‡æœŸè´§",
            "IC": "ä¸­è¯500è‚¡æŒ‡æœŸè´§", 
            "IM": "ä¸­è¯1000è‚¡æŒ‡æœŸè´§",
            "IH": "ä¸Šè¯50è‚¡æŒ‡æœŸè´§",
            "T": "10å¹´æœŸå›½å€ºæœŸè´§",
            "TF": "5å¹´æœŸå›½å€ºæœŸè´§",
            "TS": "2å¹´æœŸå›½å€ºæœŸè´§"
        }
        return products
    
    def save_to_excel(self, data, filename=None):
        """ä¿å­˜æ•°æ®åˆ°Excelæ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"cffex_data_{timestamp}.xlsx"
        
        try:
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                if isinstance(data, dict) and 'data' in data:
                    for i, table_data in enumerate(data['data']):
                        if 'rows' in table_data:
                            df = pd.DataFrame(table_data['rows'])
                            sheet_name = f"Table_{i+1}"
                            df.to_excel(writer, sheet_name=sheet_name, index=False)
                
                # æ·»åŠ å…ƒæ•°æ®sheet
                metadata = {
                    'Product ID': [data.get('product_id', '')],
                    'Date': [data.get('date', '')],
                    'Timestamp': [data.get('timestamp', '')],
                    'Success': [data.get('success', False)]
                }
                meta_df = pd.DataFrame(metadata)
                meta_df.to_excel(writer, sheet_name='Metadata', index=False)
            
            logging.info(f"æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
            return filename
            
        except Exception as e:
            logging.error(f"ä¿å­˜Excelæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    def save_to_csv(self, data, filename=None):
        """
        å°†æ•°æ®ä¿å­˜ä¸ºCSVæ ¼å¼
        Args:
            data: è¦ä¿å­˜çš„æ•°æ®
            filename: æ–‡ä»¶åï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        try:
            if not filename:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"cffex_data_{timestamp}.csv"
            
            # æ£€æŸ¥æ•°æ®æ ¼å¼
            if not isinstance(data, dict) or "data" not in data:
                logging.error("æ•°æ®æ ¼å¼ä¸æ­£ç¡®ï¼Œæ— æ³•ä¿å­˜")
                return None
            
            # å‡†å¤‡CSVæ•°æ®
            csv_data = []
            
            # æ·»åŠ å…ƒæ•°æ®æ³¨é‡Š
            csv_data.append([f"# äº§å“ä»£ç : {data.get('product_id', 'N/A')}"])
            csv_data.append([f"# æŸ¥è¯¢æ—¥æœŸ: {data.get('date', 'N/A')}"])
            csv_data.append([f"# ç”Ÿæˆæ—¶é—´: {data.get('timestamp', 'N/A')}"])
            csv_data.append([f"# æŸ¥è¯¢çŠ¶æ€: {'æˆåŠŸ' if data.get('success', False) else 'å¤±è´¥'}"])
            csv_data.append([])  # ç©ºè¡Œåˆ†éš”
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            if "error" in data:
                csv_data.append([f"# é”™è¯¯ä¿¡æ¯: {data['error']}"])
                csv_data.append([])
            else:
                # æ·»åŠ æˆäº¤é‡æ’åæ•°æ®
                if data["data"]["volume_ranking"]:
                    csv_data.append(["æˆäº¤é‡æ’å"])
                    csv_data.append(["åæ¬¡", "ä¼šå‘˜ç®€ç§°", "æˆäº¤é‡", "æ¯”ä¸Šäº¤æ˜“æ—¥å¢å‡"])
                    for record in data["data"]["volume_ranking"]:
                        csv_data.append([
                            record["rank"],
                            record["member_name"],
                            record["volume"],
                            record["change"]
                        ])
                    csv_data.append([])  # ç©ºè¡Œåˆ†éš”
                
                # æ·»åŠ æŒä¹°å•é‡æ’åæ•°æ®
                if data["data"]["buy_position_ranking"]:
                    csv_data.append(["æŒä¹°å•é‡æ’å"])
                    csv_data.append(["åæ¬¡", "ä¼šå‘˜ç®€ç§°", "æŒä¹°å•é‡", "æ¯”ä¸Šäº¤æ˜“æ—¥å¢å‡"])
                    for record in data["data"]["buy_position_ranking"]:
                        csv_data.append([
                            record["rank"],
                            record["member_name"],
                            record["volume"],
                            record["change"]
                        ])
                    csv_data.append([])  # ç©ºè¡Œåˆ†éš”
                
                # æ·»åŠ æŒå–å•é‡æ’åæ•°æ®
                if data["data"]["sell_position_ranking"]:
                    csv_data.append(["æŒå–å•é‡æ’å"])
                    csv_data.append(["åæ¬¡", "ä¼šå‘˜ç®€ç§°", "æŒå–å•é‡", "æ¯”ä¸Šäº¤æ˜“æ—¥å¢å‡"])
                    for record in data["data"]["sell_position_ranking"]:
                        csv_data.append([
                            record["rank"],
                            record["member_name"],
                            record["volume"],
                            record["change"]
                        ])
            
            # ä¿å­˜åˆ°CSVæ–‡ä»¶
            df = pd.DataFrame(csv_data)
            df.to_csv(filename, index=False, header=False, encoding='utf-8-sig')
            
            logging.info(f"æ•°æ®å·²ä¿å­˜åˆ°CSVæ–‡ä»¶: {filename}")
            return filename
            
        except Exception as e:
            logging.error(f"ä¿å­˜CSVæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    def run_daily_crawl(self, product_ids=None, save_excel=True):
        """æ‰§è¡Œæ—¥å¸¸çˆ¬å–ä»»åŠ¡"""
        if not product_ids:
            product_ids = ["IM", "IF", "IC", "IH"]  # é»˜è®¤çˆ¬å–ä¸»è¦è‚¡æŒ‡æœŸè´§
        
        results = {}
        
        for product_id in product_ids:
            logging.info(f"å¼€å§‹çˆ¬å–äº§å“: {product_id}")
            try:
                data = self.get_product_data(product_id)
                results[product_id] = data
                
                if save_excel and data and data.get('success'):
                    filename = f"cffex_{product_id}_{datetime.now().strftime('%Y%m%d')}.xlsx"
                    self.save_to_excel(data, filename)
                
                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                time.sleep(2)
                
            except Exception as e:
                logging.error(f"çˆ¬å–äº§å“{product_id}æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                results[product_id] = {"error": str(e)}
        
        return results
    
    def close(self):
        """å…³é—­çˆ¬è™«ï¼Œé‡Šæ”¾èµ„æº"""
        if self.driver:
            self.driver.quit()
        self.session.close()
        logging.info("çˆ¬è™«å·²å…³é—­")

def main():
    """ä¸»å‡½æ•°"""
    print("ä¸­é‡‘æ‰€æŒä»“æ•°æ®çˆ¬è™«ç¨‹åº")
    print("=" * 50)
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    spider = CFFEXSpider(headless=False)  # è®¾ç½®ä¸ºFalseä»¥ä¾¿è°ƒè¯•
    
    try:
        # æ˜¾ç¤ºå¯ç”¨äº§å“
        products = spider.get_available_products()
        print("å¯ç”¨äº§å“:")
        for code, name in products.items():
            print(f"  {code}: {name}")
        print()
        
        # è·å–ç”¨æˆ·è¾“å…¥
        product_id = input("è¯·è¾“å…¥äº§å“ä»£ç  (é»˜è®¤IM): ").strip().upper()
        if not product_id:
            product_id = "IM"
        
        # å›ºå®šä½¿ç”¨2025-09-13æ—¥æœŸè¿›è¡Œæµ‹è¯•ï¼ˆå› ä¸ºå½“å¤©æ•°æ®è¿˜æœªç”Ÿæˆï¼‰
        date = "2025-09-12"
        print(f"ä½¿ç”¨å›ºå®šæµ‹è¯•æ—¥æœŸ: {date}")
        
        print(f"\nå¼€å§‹çˆ¬å–äº§å“ {product_id} çš„æ•°æ®...")
        
        # æ‰§è¡Œçˆ¬å–
        result = spider.get_product_data(product_id, date)
        
        if result:
            print("\nçˆ¬å–ç»“æœ:")
            print(json.dumps(result, ensure_ascii=False, indent=2))
            
            # ä¿å­˜ä¸ºCSVæ ¼å¼
            if result.get('success'):
                csv_filename = spider.save_to_csv(result)
                if csv_filename:
                    print(f"\nâœ… CSVæ•°æ®å·²ä¿å­˜åˆ°: {csv_filename}")
                    print(f"\nğŸ‰ æ•°æ®ä¿å­˜æˆåŠŸ")
                else:
                    print("\nâŒ æ–‡ä»¶ä¿å­˜å¤±è´¥")
            else:
                print(f"\nçˆ¬å–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        else:
            print("æœªè·å–åˆ°ä»»ä½•æ•°æ®")
    
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
    finally:
        spider.close()

if __name__ == "__main__":
    main()